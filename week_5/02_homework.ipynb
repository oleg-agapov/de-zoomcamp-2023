{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c52bc45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/24 18:05:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/24 18:05:30 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/02/24 18:05:30 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804696aa",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Install Spark and PySpark\n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "\n",
    "- 3.3.2 (+)\n",
    "- 2.1.4\n",
    "- 1.2.3\n",
    "- 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3cbcd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd473c19",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "HVFHW June 2021\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.\n",
    "\n",
    "We will use this dataset for all the remaining questions.\n",
    "\n",
    "Repartition it to 12 partitions and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "\n",
    "- 2MB\n",
    "- 24MB (+)\n",
    "- 100MB\n",
    "- 250MB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33949a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_spark_init.ipynb  fhvhv_tripdata_2021-06.csv.gz\r\n",
      "02_homework.ipynb    taxi+_zone_lookup.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4af9790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c5ac1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>SR_Flag</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:02:41</td>\n",
       "      <td>2021-06-01 00:07:46</td>\n",
       "      <td>174</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:16:16</td>\n",
       "      <td>2021-06-01 00:21:14</td>\n",
       "      <td>32</td>\n",
       "      <td>254</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:27:01</td>\n",
       "      <td>2021-06-01 00:42:11</td>\n",
       "      <td>240</td>\n",
       "      <td>127</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B02764</td>\n",
       "      <td>2021-06-01 00:46:08</td>\n",
       "      <td>2021-06-01 00:53:45</td>\n",
       "      <td>127</td>\n",
       "      <td>235</td>\n",
       "      <td>N</td>\n",
       "      <td>B02764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B02510</td>\n",
       "      <td>2021-06-01 00:45:42</td>\n",
       "      <td>2021-06-01 01:03:33</td>\n",
       "      <td>144</td>\n",
       "      <td>146</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dispatching_base_num      pickup_datetime     dropoff_datetime  \\\n",
       "0               B02764  2021-06-01 00:02:41  2021-06-01 00:07:46   \n",
       "1               B02764  2021-06-01 00:16:16  2021-06-01 00:21:14   \n",
       "2               B02764  2021-06-01 00:27:01  2021-06-01 00:42:11   \n",
       "3               B02764  2021-06-01 00:46:08  2021-06-01 00:53:45   \n",
       "4               B02510  2021-06-01 00:45:42  2021-06-01 01:03:33   \n",
       "\n",
       "   PULocationID  DOLocationID SR_Flag Affiliated_base_number  \n",
       "0           174            18       N                 B02764  \n",
       "1            32           254       N                 B02764  \n",
       "2           240           127       N                 B02764  \n",
       "3           127           235       N                 B02764  \n",
       "4           144           146       N                    NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('fhvhv_tripdata_2021-06.csv.gz', nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d1c0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfe6113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField('dispatching_base_num', StringType(), True), \n",
    "    StructField('pickup_datetime', TimestampType(), True), \n",
    "    StructField('dropoff_datetime', TimestampType(), True), \n",
    "    StructField('PULocationID', IntegerType(), True), \n",
    "    StructField('DOLocationID', IntegerType(), True), \n",
    "    StructField('SR_Flag', StringType(), True), \n",
    "    StructField('Affiliated_base_number', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f9aabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.schema(schema).csv('fhvhv_tripdata_2021-06.csv.gz', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4bf80e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31c01287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/24 18:23:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: dispatching_base_num, pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, SR_Flag, Affiliated_base_number\n",
      " Schema: dispatching_base_num, pickup_datetime, dropoff_datetime, pickup_location_id, dropoff_location_id, sr_flag, affiliated_base_number\n",
      "Expected: pickup_location_id but found: PULocationID\n",
      "CSV file: file:///home/oleg/spark/fhvhv_tripdata_2021-06.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.repartition(12).write.parquet('fhvhv_tripdata_2021_06.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7c4fd01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 284M\r\n",
      "-rw-r--r-- 1 oleg oleg   0 Feb 24 18:25 _SUCCESS\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:24 part-00000-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:24 part-00001-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:24 part-00002-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:24 part-00003-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:25 part-00004-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:25 part-00005-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:24 part-00006-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:25 part-00007-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:25 part-00008-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:25 part-00009-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:25 part-00010-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 oleg oleg 24M Feb 24 18:25 part-00011-ba4f04e8-7733-4463-894e-14fe852248cb-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh fhvhv_tripdata_2021_06.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278a5aa",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Count records.\n",
    "\n",
    "How many taxi trips were there on June 15?\n",
    "\n",
    "Consider only trips that started on June 15.\n",
    "\n",
    "- 308,164\n",
    "- 12,856\n",
    "- 452,470 (+)\n",
    "- 50,982 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b02b2c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " dispatching_base_num   | B02764              \n",
      " pickup_datetime        | 2021-06-01 00:02:41 \n",
      " dropoff_datetime       | 2021-06-01 00:07:46 \n",
      " PULocationID           | 174                 \n",
      " DOLocationID           | 18                  \n",
      " SR_Flag                | N                   \n",
      " Affiliated_base_number | B02764              \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "214a0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35c8cea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .filter(F.col('pickup_datetime').between('2021-06-15', '2021-06-15 23:59:59'))\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb67d6f",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Longest trip for each day.\n",
    "\n",
    "Now calculate the duration for each trip. How long was the longest trip in Hours?\n",
    "\n",
    "- 66.87 Hours (+)\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6407e833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|max(trip_duration)|\n",
      "+------------------+\n",
      "| 66.87888888888888|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .select('dispatching_base_num', 'pickup_datetime', 'dropoff_datetime')\n",
    "    .withColumn(\n",
    "        'trip_duration', \n",
    "        (F.unix_timestamp('dropoff_datetime') - F.unix_timestamp('pickup_datetime')) / 60 / 60\n",
    "    )\n",
    "    .agg(F.max('trip_duration'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f943b",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "User Interface.\n",
    "\n",
    "Spark’s User Interface which shows application's dashboard runs on which local port?\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- 4040 (+)\n",
    "- 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "545f1c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://de-zoomcamp-2023-vm.europe-west6-a.c.booming-landing-375221.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=test>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae23d2",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Most frequent pickup location zone.\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark.\n",
    "\n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?\n",
    "\n",
    "- East Chelsea\n",
    "- Astoria\n",
    "- Union Sq\n",
    "- Crown Heights North (+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b071c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_zones = StructType([\n",
    "    StructField('LocationID', IntegerType(), True),\n",
    "    StructField('Borough', StringType(), True),\n",
    "    StructField('Zone', StringType(), True),\n",
    "    StructField('service_zone', StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "facbff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.schema(schema_zones).csv('taxi+_zone_lookup.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c992b7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68ed1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- LocationID: integer (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- Zone: string (nullable = true)\n",
      " |-- service_zone: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59e5db7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ebd10fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 28:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|               Zone| trips|\n",
      "+-------------------+------+\n",
      "|Crown Heights North|231279|\n",
      "|       East Village|221244|\n",
      "|        JFK Airport|188867|\n",
      "|     Bushwick South|187929|\n",
      "|      East New York|186780|\n",
      "+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df\n",
    "    .join(df_zones, F.col('PULocationID') == F.col('LocationID'), 'left')\n",
    "    .groupBy('Zone')\n",
    "    .agg(F.count('pickup_datetime').alias('trips'))\n",
    "    .orderBy(-F.col('trips'))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056e736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039a9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66716ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd87f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
